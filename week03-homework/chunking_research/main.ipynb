{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25084a22",
   "metadata": {},
   "source": [
    "# 作业一: 探索 LlamaIndex 中的句子切片检索及其参数影响分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b9731",
   "metadata": {},
   "source": [
    "## 文本数据集\n",
    "\n",
    "* [doc1.txt](./docs/txt/doc1.txt)\n",
    "* [doc2.txt](./docs/txt/doc2.txt)\n",
    "* [doc3.txt](./docs/txt/doc3.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c3fcc",
   "metadata": {},
   "source": [
    "## 配置 llamaindex\n",
    "\n",
    "使用 qwen 系列，兼容 OpenAI 接口的大模型和嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e235d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "Settings.llm = OpenAILike(\n",
    "    model=\"qwen-plus-latest\",\n",
    "    api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    is_chat_model=True,\n",
    ")\n",
    "\n",
    "Settings.embed_model = DashScopeEmbedding(\n",
    "    model_name=\"text-embedding-v4\",\n",
    "    embed_batch_size=6,\n",
    "    embed_input_length=8192,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b375e",
   "metadata": {},
   "source": [
    "## 参数对比实验\n",
    "\n",
    "比较不同参数组合对**检索相关性**和**生成回答质量**的影响\n",
    "- 检索到的上下文是否包含答案\n",
    "- LLM 生成的回答是否准确完整\n",
    "- 上下文冗余程度（主观评分 1–5）\n",
    "- 制作对比表格或图表展示结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae7abe",
   "metadata": {},
   "source": [
    "### 定义 evaluate_splitter 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954fe249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.indices import VectorStoreIndex\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.schema import TransformComponent\n",
    "\n",
    "\n",
    "def evaluate_splitter(\n",
    "    splitter: TransformComponent,\n",
    "    documents: Sequence[Document],\n",
    "    query: str,\n",
    "    splitter_description: str,\n",
    ") -> None:\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        transformations=[splitter],\n",
    "    )\n",
    "\n",
    "    if splitter_description == \"Sentence Window\":\n",
    "        query_engine = index.as_query_engine(\n",
    "            similarity_top_k=5,\n",
    "            streaming=True,\n",
    "            node_postprocessors=[\n",
    "                MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        query_engine = index.as_query_engine()\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    print(f\"\\n=================分块器: {splitter_description}=================\")\n",
    "    print(f\"查询: {query}\\n回答: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9cd07",
   "metadata": {},
   "source": [
    "### 比较不同参数组合对**检索相关性**和**生成回答质量**的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243ffd4",
   "metadata": {},
   "source": [
    "1. 使用不同的 chunk_size 参数的 SentenceSplitter 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "\n",
    "# 加载文档\n",
    "documents = SimpleDirectoryReader(input_files=[\"./docs/txt/doc1.txt\"]).load_data()\n",
    "\n",
    "# 不同 chunk_size 参数的实例\n",
    "sentence_splitter1 = SentenceSplitter(chunk_size=64, chunk_overlap=24)\n",
    "sentence_splitter2 = SentenceSplitter(chunk_size=128, chunk_overlap=24)\n",
    "sentence_splitter3 = SentenceSplitter(chunk_size=512, chunk_overlap=24)\n",
    "\n",
    "query = \"为什么说算法偏见问题同样不容忽视？\"\n",
    "evaluate_splitter(\n",
    "    sentence_splitter1,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter1(chunk_size=64, chunk_overlap=24)\",\n",
    ")\n",
    "evaluate_splitter(\n",
    "    sentence_splitter2,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter1(chunk_size=128, chunk_overlap=24)\",\n",
    ")\n",
    "evaluate_splitter(\n",
    "    sentence_splitter3,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter2(chunk_size=512, chunk_overlap=24)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45d3f6",
   "metadata": {},
   "source": [
    "2. 使用不同 chunk_overlap 参数的 SentenceSplitter 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "\n",
    "# 加载文档\n",
    "documents = SimpleDirectoryReader(input_files=[\"./docs/txt/doc2.txt\"]).load_data()\n",
    "\n",
    "sentence_splitter4 = SentenceSplitter(chunk_size=128, chunk_overlap=0)\n",
    "sentence_splitter5 = SentenceSplitter(chunk_size=128, chunk_overlap=16)\n",
    "sentence_splitter6 = SentenceSplitter(chunk_size=128, chunk_overlap=32)\n",
    "sentence_splitter7 = SentenceSplitter(chunk_size=128, chunk_overlap=64)\n",
    "\n",
    "query = \"量子计算的前景光明，表现在哪些方面？\"\n",
    "\n",
    "evaluate_splitter(\n",
    "    sentence_splitter4,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter1(chunk_size=128, chunk_overlap=0)\",\n",
    ")\n",
    "evaluate_splitter(\n",
    "    sentence_splitter5,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter2(chunk_size=128, chunk_overlap=16)\",\n",
    ")\n",
    "\n",
    "evaluate_splitter(\n",
    "    sentence_splitter6,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter2(chunk_size=128, chunk_overlap=32)\",\n",
    ")\n",
    "\n",
    "evaluate_splitter(\n",
    "    sentence_splitter7,\n",
    "    documents,\n",
    "    query,\n",
    "    \"sentence_splitter2(chunk_size=128, chunk_overlap=64)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2cd122",
   "metadata": {},
   "source": [
    "3. 使用不同 splitter 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fe40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    SentenceSplitter,\n",
    "    SentenceWindowNodeParser,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "\n",
    "# 加载文档\n",
    "documents = SimpleDirectoryReader(input_files=[\"./docs/txt/doc3.txt\"]).load_data()\n",
    "\n",
    "# 句子切片\n",
    "sentence_splitter = SentenceSplitter(chunk_size=128, chunk_overlap=32)\n",
    "# Token 切片\n",
    "token_splitter = TokenTextSplitter(chunk_size=128, chunk_overlap=32, separator=\"。\")\n",
    "# 句子窗口切片\n",
    "sentence_window_splitter = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "query = \"为什么说《巴黎协定》代表了全球气候治理的重要里程碑？\"\n",
    "evaluate_splitter(\n",
    "    splitter=sentence_splitter,\n",
    "    documents=documents,\n",
    "    query=query,\n",
    "    splitter_description=\"Sentence\",\n",
    ")\n",
    "evaluate_splitter(\n",
    "    splitter=token_splitter,\n",
    "    documents=documents,\n",
    "    query=query,\n",
    "    splitter_description=\"Token\",\n",
    ")\n",
    "evaluate_splitter(\n",
    "    splitter=sentence_window_splitter,\n",
    "    documents=documents,\n",
    "    query=query,\n",
    "    splitter_description=\"Sentence Window\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week03-homework (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
